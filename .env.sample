# Copy to `.env` (this file is gitignored) and fill in secrets.

# Database
PORTFOLIO_DB_PASSWORD=change-me
METABASE_DB_PASSWORD=change-me

# Admin UI auth (Basic Auth + JWT)
ADMIN_USER=admin
ADMIN_PASS=change-me
JWT_ISSUER=portfolio-manager

# Bind addresses (keep local by default)
ADMIN_SPRING_BIND=127.0.0.1
ADMIN_FRONTEND_BIND=127.0.0.1

# Knowledge Base (KB)
# - KB endpoints are gated by KB_ENABLED and an enabled LLM provider
KB_ENABLED=true

# - Enables the (currently stubbed) LlmExtractorService for dossier extraction runs
KB_LLM_ENABLED=false

# LLM provider (OpenAI via Responses API)
# - Set LLM_PROVIDER=openai to enable the LLM client
LLM_PROVIDER=none
LLM_PROVIDER_MODEL=gpt-5-nano
LLM_PROVIDER_BASE_URL=https://api.openai.com/v1
LLM_EXTERNAL_PROVIDER=false

# Prefer LLM_PROVIDER_API_KEY; OPENAI_API_KEY is supported as a fallback.
LLM_PROVIDER_API_KEY=
#OPENAI_API_KEY=

# Local LLM (Ollama) + SearxNG (optional)
# - Use docker compose --profile llm (internal) or --profile llm-dev (localhost)
# - Switch the LLM provider to Ollama by setting:
#   LLM_PROVIDER=ollama
#   LLM_PROVIDER_MODEL=llama3.1:8b
#   LLM_PROVIDER_BASE_URL=http://ollama:11434/v1
#   LLM_EXTERNAL_PROVIDER=false
# - SearxNG settings (local websearch):
KB_SEARCH_PROVIDER=searxng
KB_SEARCH_BASE_URL=http://searxng:8080
KB_SEARCH_MAX_RESULTS=8
KB_SEARCH_MAX_SNIPPET_CHARS=1200
KB_SEARCH_TIMEOUT_SECONDS=15
SEARXNG_SECRET=change-me
